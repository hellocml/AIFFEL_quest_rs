{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7HbXZEyhnet",
    "outputId": "24242d7d-9018-432f-cf83-1824f46091fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting loralib\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: loralib\n",
      "Successfully installed loralib-0.1.2\n",
      "Collecting trl\n",
      "  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.9.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.11.12)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n",
      "Downloading trl-0.25.1-py3-none-any.whl (465 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.25.1\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install loralib\n",
    "!pip install trl\n",
    "!pip install accelerate\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOcvQq0Bg35h",
    "outputId": "044393e3-2e44-405f-b4e2-be0f6f20c6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoChatGPT'...\n",
      "remote: Enumerating objects: 304, done.\u001b[K\n",
      "remote: Total 304 (delta 0), reused 0 (delta 0), pack-reused 304 (from 1)\u001b[K\n",
      "Receiving objects: 100% (304/304), 57.72 MiB | 10.50 MiB/s, done.\n",
      "Resolving deltas: 100% (123/123), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/airobotlab/KoChatGPT\n",
    "!cp -r /content/KoChatGPT/colossalai_ChatGPT_230319/chatgpt /content/chatgpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq31swmZh3au",
    "outputId": "5419a620-975a-478b-88db-7fdb667b7641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수정 완료: chatgpt/trainer/callbacks/save_checkpoint.py\n",
      "✅ 수정 완료: chatgpt/trainer/strategies/__init__.py\n",
      "✅ 수정 완료: chatgpt/dataset/reward_dataset.py\n",
      "⚠️ chatgpt/trainer/strategies/__init__.py 수정할 내용이 없습니다.\n",
      "⚠️ chatgpt/dataset/reward_dataset.py 파일의 8번째 줄이 예상과 다릅니다.\n",
      "   예상: from tqdm import tqdm\n",
      "   실제: class RewardDataset(Dataset):\n",
      "⚠️ chatgpt/dataset/reward_dataset.py 수정할 내용이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "modifications = [\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/callbacks/save_checkpoint.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 3, \"old\": \"from chatgpt.trainer.strategies import ColossalAIStrategy, Strategy\",\n",
    "             \"new\": \"from chatgpt.trainer.strategies import Strategy\"},\n",
    "            {\"line\": 71, \"old\": \"only_rank0 = not isinstance(self.strategy, ColossalAIStrategy)\",\n",
    "             \"new\": \"            only_rank0 = not isinstance(self.strategy)\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/strategies/__init__.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 1, \"old\": \"from .colossalai import ColossalAIStrategy\", \"new\": \"\"},  # 삭제\n",
    "            {\"line\": 5, \"old\": \"__all__ = ['Strategy', 'NaiveStrategy', 'DDPStrategy', 'ColossalAIStrategy']\",\n",
    "             \"new\": \"__all__ = ['Strategy', 'NaiveStrategy', 'DDPStrategy']\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/dataset/reward_dataset.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 3, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/trainer/strategies/__init__.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 8, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"file\": \"chatgpt/dataset/reward_dataset.py\",\n",
    "        \"changes\": [\n",
    "            {\"line\": 8, \"old\": \"from tqdm import tqdm\", \"new\": \"from tqdm.notebook import tqdm\"},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def modify_file(file_path, changes):\n",
    "    \"\"\"파일에서 지정된 줄을 찾아 내용을 수정하는 함수\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ 파일이 존재하지 않습니다: {file_path}\")\n",
    "        return\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    modified = False\n",
    "\n",
    "    for change in changes:\n",
    "        line_index = change[\"line\"]\n",
    "        if 0 <= line_index < len(lines):\n",
    "            if lines[line_index].strip() == change[\"old\"]:\n",
    "                lines[line_index] = change[\"new\"] + \"\\n\"\n",
    "                modified = True\n",
    "            else:\n",
    "                print(f\"⚠️ {file_path} 파일의 {change['line']}번째 줄이 예상과 다릅니다.\")\n",
    "                print(f\"   예상: {change['old']}\")\n",
    "                print(f\"   실제: {lines[line_index].strip()}\")\n",
    "\n",
    "    if modified:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.writelines(lines)\n",
    "        print(f\"✅ 수정 완료: {file_path}\")\n",
    "    else:\n",
    "        print(f\"⚠️ {file_path} 수정할 내용이 없습니다.\")\n",
    "\n",
    "for mod in modifications:\n",
    "    modify_file(mod[\"file\"], mod[\"changes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBkLRYGAh8cS",
    "outputId": "77c69282-d437-4181-9b3b-1b811d752849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:2.9.0+cu126\n",
      "Cuda version: 12.6\n",
      "transformers version: 4.57.2\n",
      "GPU 사용 가능여부: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr-MwUXMiKSF"
   },
   "source": [
    "2. Base model and Dataset for RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1C5Ff6DiUZY"
   },
   "source": [
    " backbone 모델로 사용할 KoGPT-2의 성능을 잠시 확인해볼까요?\n",
    "\n",
    "허깅페이스의 transformers를 사용하면 토크나이저와 모델을 간단히 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "3f6f206bb7f744e7ad0277a1f7b929d2",
      "2ff8c5fedb974ab1a667172fbb7ddd35",
      "8ec788e75c4645a484b84bd1d382ef26",
      "bdde90730b3547c49e7ea58dc94378e0",
      "a08c007a91854ad79b7f0a9a065b3f1c",
      "008527e6c5804d8c96d5b9184007f024",
      "3a88a05ef65443e09eccba1b7ef1fcae",
      "ed845a724be445b6b0a1736125ab1abb",
      "9e66723cdcc149ed806568661ed8890e",
      "cc7fc7b9cdca4cb89bd55471e05d371d",
      "ff9312a4d04248d99919a8a947f2e241",
      "271a0ba2420e438abe4e4993896f57f2",
      "77722495fe084fd2897b1e815d2f9fee",
      "c6e0c1192b4144af8d71af9aa62c4e52",
      "dc9344d479714251b5313cd6e48bb1d6",
      "bd9acf347382422e862ae2fff89045c9",
      "6d603d5271c54378a1302747bce81ed0",
      "f4cc3e0c6e024eab9be56593ef76cd89",
      "8122ed7d8b7d457391b0f50f1e23d72b",
      "aeae18ddbc2a42c2b5dc1badbab72e48",
      "08ab5e6c7b08494d9130641665b1566a",
      "deb7260e6e80440680f99aa12e4883d0",
      "c0e11d3e90354a96b25df6ec58f70e82",
      "7216a312d16b4a28bc020c4f447851d2",
      "f9827ac8387e48a2bd079af05ff2e2ec",
      "22b5f2ff37f64856936830a1bb31df37",
      "4baadae00ad547429cfab3bcdd613d9b",
      "2ea3be2cb9c347a0b7f433c903d9723b",
      "44776cf11e6b4509b3dfe330de1dca3f",
      "82acb7607391429ba02249587f16ed5a",
      "d2becb4c2cf7476ab35ccbc476772032",
      "1d9b412e680f4623b908a7c0bb1a54c7",
      "492f185bc8e84c5a939eec09c0b857a0",
      "4edbac73dff74b6ca054dc6dff964789",
      "62d8e675246043dcad3006f40a5217f2",
      "26fd0fd3124c4778b4c17757c40cbb80",
      "315dbc7cb1e141f18e23336a5dcc661b",
      "65554f82ec1c4662801ddf0ffe76d439",
      "4c84995329f5496f88419760b160eff9",
      "c223ee701aaf4cc788fb9ec1c13fde53",
      "1209f2cc5b294d72b8514cf1980184ef",
      "6ae0c0f3afe24148bf56de789f608311",
      "572bb05aa8074b629f9a9da38bba9887",
      "ed017209de9541ab983f4dd5bccdc065"
     ]
    },
    "id": "XWEv8tFviCoa",
    "outputId": "a5802dd7-2460-4b12-cd28-2ca8ba966ea3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6f206bb7f744e7ad0277a1f7b929d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271a0ba2420e438abe4e4993896f57f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e11d3e90354a96b25df6ec58f70e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edbac73dff74b6ca054dc6dff964789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1OzvmpMiXm9",
    "outputId": "8e267af7-e150-4cc4-cff4-5f6b39b71eca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000000019884624838656"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우리가 사용할 모델의 토크나이저가 입력받아 처리할 수 있는 최대 토큰 수를 확인\n",
    "\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5DtBPZ9imA_",
    "outputId": "fbd5d342-cef4-4fe6-b6a1-05d3fbb91a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kogpt-2는 어떻게 토크나이징을 하는지 잠시 확인\n",
    "model.config.n_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LCEliMSxisMJ"
   },
   "outputs": [],
   "source": [
    "input_txt = \"바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ggdcrf94ivsh"
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_txt).tokens()\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "3iK88_kei0ZK",
    "outputId": "3498b018-55ea-4ad2-b823-13b2efd7f09b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-fb120e5f-69d6-41ba-aa34-908fd6bfbe78\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kogpt-2_tokens</th>\n",
       "      <td>▁바람</td>\n",
       "      <td>도</td>\n",
       "      <td>▁없는</td>\n",
       "      <td>▁공중에</td>\n",
       "      <td>▁수직</td>\n",
       "      <td>의</td>\n",
       "      <td>▁파</td>\n",
       "      <td>문을</td>\n",
       "      <td>▁내</td>\n",
       "      <td>이며</td>\n",
       "      <td>▁고</td>\n",
       "      <td>요</td>\n",
       "      <td>히</td>\n",
       "      <td>▁떨어지는</td>\n",
       "      <td>▁오동</td>\n",
       "      <td>잎은</td>\n",
       "      <td>▁누</td>\n",
       "      <td>구의</td>\n",
       "      <td>▁발자</td>\n",
       "      <td>취</td>\n",
       "      <td>▁입</td>\n",
       "      <td>니까</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input_IDs</th>\n",
       "      <td>10891</td>\n",
       "      <td>7235</td>\n",
       "      <td>9712</td>\n",
       "      <td>49207</td>\n",
       "      <td>14438</td>\n",
       "      <td>8143</td>\n",
       "      <td>9203</td>\n",
       "      <td>9941</td>\n",
       "      <td>9094</td>\n",
       "      <td>9639</td>\n",
       "      <td>9065</td>\n",
       "      <td>8084</td>\n",
       "      <td>8811</td>\n",
       "      <td>21215</td>\n",
       "      <td>34769</td>\n",
       "      <td>19985</td>\n",
       "      <td>9669</td>\n",
       "      <td>10139</td>\n",
       "      <td>21626</td>\n",
       "      <td>8408</td>\n",
       "      <td>9241</td>\n",
       "      <td>23775</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb120e5f-69d6-41ba-aa34-908fd6bfbe78')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fb120e5f-69d6-41ba-aa34-908fd6bfbe78 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fb120e5f-69d6-41ba-aa34-908fd6bfbe78');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ee7f376d-cb7c-4e77-bd74-6bead60e11ea\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee7f376d-cb7c-4e77-bd74-6bead60e11ea')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ee7f376d-cb7c-4e77-bd74-6bead60e11ea button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_03cf5166-5b0e-431d-bfeb-9a6a6cde2cbf\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_03cf5166-5b0e-431d-bfeb-9a6a6cde2cbf button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   0     1     2      3      4     5     6     7     8     9   \\\n",
       "kogpt-2_tokens    ▁바람     도   ▁없는   ▁공중에    ▁수직     의    ▁파    문을    ▁내    이며   \n",
       "Input_IDs       10891  7235  9712  49207  14438  8143  9203  9941  9094  9639   \n",
       "\n",
       "                  10    11    12     13     14     15    16     17     18  \\\n",
       "kogpt-2_tokens    ▁고     요     히  ▁떨어지는    ▁오동     잎은    ▁누     구의    ▁발자   \n",
       "Input_IDs       9065  8084  8811  21215  34769  19985  9669  10139  21626   \n",
       "\n",
       "                  19    20     21   22  \n",
       "kogpt-2_tokens     취    ▁입     니까    .  \n",
       "Input_IDs       8408  9241  23775  389  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 60\n",
    "df = pd.DataFrame([tokens, input_ids[0]], index=[\"kogpt-2_tokens\", \"Input_IDs\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "uSHKupbwi2N5",
    "outputId": "bd9393c1-4bc8-43fe-a937-f58e7d58c2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.'\n",
      "\"그렇다면 그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리\n"
     ]
    }
   ],
   "source": [
    "# 디코딩 성능 확인\n",
    "\n",
    "max_length=128\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqGVsADwjHAm"
   },
   "source": [
    "시퀀스가 반복되어 출력되는군요.\n",
    "\n",
    "그리디 서치 디코딩시 발견되는 전형적인 현상입니다.\n",
    "\n",
    "이번엔 빔 서치 디코딩을 사용하고 n-gram 패널티까지 부과해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aa43mE1fi8ad",
    "outputId": "86f0f5ed-38ee-4450-d031-0f6af96c74e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.'\n",
      "\"그렇지 않습니다.\"\n",
      "\"어떻게 된 일입니까?\"\n",
      "그녀는 고개를 갸웃거렸다.\n",
      "\"아니, 그게 무슨 말씀이신지 모르겠습니다만.\"\n",
      "\"무슨 말씀인지 알 수가 없군요.\"\n",
      "아무런 대답도 하지 않은 채 그녀는 고개를 끄덕였다.\n",
      "\"그래, 알았어.\"\n",
      "그녀의 눈에서 눈물이 주르륵 흘러내렸다.\n",
      "그녀가 다시 입을 열었다.\n",
      "\"정말 죄송합니다, 고마워요, 고맙습니다\"\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=10, no_repeat_ngram_size=2,do_sample=False)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfpoMaYljJTf",
    "outputId": "cb3c2812-3ea3-478b-f22f-2d4f6518dfbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "\n",
    "import json\n",
    "data_path_1_SFT = 'KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8xIIAyzjWx3"
   },
   "source": [
    "입력 시퀀스와 별 상관 없어 보이는 긴 문단이 생성됩니다.\n",
    "\n",
    "그럼에도 생성된 문단은 제법 맥락을 갖춘 듯 보입니다.\n",
    "\n",
    "하지만 문장 간의 정합성이나 일관성은 다소 떨어지는 부분도 관찰됩니다.\n",
    "\n",
    "이번엔 샘플링 기법까지 추가해 보겠습니다.\n",
    "\n",
    "실행 되었습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dqjPtDMjZCZ",
    "outputId": "62db6389-9724-4dc6-8f20-0b77ab1eea29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.'\n",
      "'아, 아닙니다!'\n",
      "\"그렇지요. 저, 저는 한 번도 저를 본 적이 없었습니다.\"\n",
      "\"당신은 저의 어머니입니다.\"\n",
      "누구의 말뜻을 알아듣지 못하고 <unk><unk>거렸다.\n",
      "'아니, 아니야. 당신이 저에게 뭘 물어보려고 하셨는지 모르겠소.'\n",
      "그렇게 말했어야 했다.\n",
      "\"이제부터 당신 어머니에 대해 알아보도록 하겠습니다. 혹시라도 제 어머니께 무슨 말을 해줄 수 있으신지요?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7, no_repeat_ngram_size=2,\n",
    "                             do_sample=True, temperature=2.0, top_k=50)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InQxkSYzllCJ"
   },
   "source": [
    "Q. generate함수의 인자로 사용한 temperature, top_k 값은 어떤 효과를 주는 옵션인가요?\n",
    "`temperature`: temperature 값을 낮추면(예: temperature=0.5) 확률이 높은 단어들이 더욱 우세하게 선택되며, 보수적인 생성이 이루어집니다.\n",
    "반대로 값을 높이면(예: temperature=1.5) 확률이 낮은 단어들도 더 자주 선택되며, 더 창의적이지만 불안정한 결과가 나올 수 있습니다.\n",
    "\n",
    "`top_k`: 샘플링 시 상위 k개의 단어 후보만 고려하여 나머지를 무시하는 방식입니다.\n",
    "예를 들어, top_k=50이면, 확률이 높은 상위 50개의 단어만 샘플링 대상이 되고, 그 외 단어는 제외됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lc5Z5PipjZmu",
    "outputId": "cbc61543-f666-4671-afe8-fd183b24d6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\"\n",
      "\"그런데 그게 무슨 뜻입니까?\"\n",
      "나는 고개를 끄덕이며 물었다.\n",
      "\"아니오, 아니오.\"\n",
      "\"무슨 뜻인지 알 수 없군요.\"\n",
      "그제야 나는 한숨을 내쉬었다.\n",
      "\"어떻게 해야 할까요? 어떻게 해야 할지 모르겠습니다.\"\n",
      "내가 입을 다물자 나는 다시 한 번 고개를 갸웃거렸다.\n",
      "\"글쎄요, 그건 그렇고 말이에요. 저는 그걸로 충분하다고 생각합니다.\"\n",
      "그러자 그제서야 나는 입을 열었다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top_p 샘플링 기법\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7, no_repeat_ngram_size=2,\n",
    "                             do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQGlrDhhn2ty",
    "outputId": "0987989b-4497-4b95-bad5-54fd8c0b3ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "import json\n",
    "data_path_1_SFT = 'KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-uAGm04Pd1W",
    "outputId": "0a8d1b01-7080-4a5d-8f73-d42bda280903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm에 사용할 데이터셋확인\n",
    "data_path_2_RM = 'KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fE1u_bx_PpBY",
    "outputId": "5a3718bb-12a5-429d-862e-82095b8b3a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ppo학습에 쓰일 데이터\n",
    "data_path_3_PPO = 'KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BlLo_8yR8u9"
   },
   "source": [
    "3. Supervised Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8H24O80pRBav"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rPlhs8F0SORk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxcbye11SVWM"
   },
   "source": [
    "kogpt-2를 instruction dataset으로 SFT를 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HHD5ZAeSWwg",
    "outputId": "a8bb5e7f-d636-460e-d7df-aae80828b19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<usr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"<sys>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t5: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t6: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t7: AddedToken(\"<d>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t8: AddedToken(\"</d>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t9: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t10: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t11: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t12: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t13: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t14: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t15: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t16: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t17: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t18: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t19: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t20: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t21: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t22: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t23: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t24: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t25: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t26: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t27: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t28: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t29: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t30: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t31: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t33: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t34: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t35: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t36: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t37: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t38: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t39: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t40: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t41: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t42: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t43: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t44: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t45: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t46: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t47: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t48: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t49: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t51: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t52: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t53: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t54: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t55: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t56: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t57: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t58: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t59: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t60: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t61: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t62: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t63: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t64: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t65: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t66: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t67: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t68: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t69: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t70: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t71: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t72: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t73: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t74: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t75: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t76: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t77: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t78: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t79: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t80: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t81: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t82: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t83: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t84: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t85: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t86: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t87: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t88: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t89: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t90: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t91: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t92: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t93: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t94: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t95: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t96: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t97: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t98: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t99: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t104: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t105: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t106: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t107: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t108: AddedToken(\"<unused99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t109: AddedToken(\":-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t110: AddedToken(\":)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t111: AddedToken(\"-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t112: AddedToken(\"(-:\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t113: AddedToken(\"(:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t114: AddedToken(\"(:-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t115: AddedToken(\"-}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t116: AddedToken(\"8-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t117: AddedToken(\"'-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t118: AddedToken(\":-#\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t119: AddedToken(\":-*\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t120: AddedToken(\":-/\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t121: AddedToken(\":->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t122: AddedToken(\":-@\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t123: AddedToken(\":-d\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t124: AddedToken(\":-V\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t125: AddedToken(\":-X\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t126: AddedToken(\":-\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t127: AddedToken(\":-]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128: AddedToken(\";-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t129: AddedToken(\">;->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t130: AddedToken(\";^)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t131: AddedToken(\"%-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t132: AddedToken(\"):-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t133: AddedToken(\"3:]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t134: AddedToken(\":-&\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t135: AddedToken(\"8:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t136: AddedToken(\":-)8<\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t137: AddedToken(\":-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t138: AddedToken(\":-6\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t139: AddedToken(\"+:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t140: AddedToken(\"O:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t141: AddedToken(\":-<\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t142: AddedToken(\":-?\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t143: AddedToken(\":-E\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t144: AddedToken(\":-Q\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t145: AddedToken(\":-}X\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t146: AddedToken(\":-[\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t147: AddedToken(\":-a\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t148: AddedToken(\":-{\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t149: AddedToken(\":-{}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t150: AddedToken(\":^)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151: AddedToken(\"<:-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t152: AddedToken(\":=)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t153: AddedToken(\">:->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t154: AddedToken(\">:-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t155: AddedToken(\"@:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t156: AddedToken(\"@:-}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t157: AddedToken(\"C=:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t158: AddedToken(\"X:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t159: AddedToken(\"[:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t160: AddedToken(\"[:]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t161: AddedToken(\"{:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t162: AddedToken(\"l^o\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t163: AddedToken(\"}:^#)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t164: AddedToken(\":-(=)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t165: AddedToken(\"O-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t166: AddedToken(\":-3\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t167: AddedToken(\":=\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t168: AddedToken(\":-\"\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t169: AddedToken(\"P-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t170: AddedToken(\"?-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t171: AddedToken(\"d:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t172: AddedToken(\":8)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t173: AddedToken(\":-7\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t174: AddedToken(\"):-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t175: AddedToken(\":/\\)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t176: AddedToken(\"8(:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t177: AddedToken(\"([(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t178: AddedToken(\":-(*)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t179: AddedToken(\"&-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t180: AddedToken(\":-e\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t181: AddedToken(\":(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t182: AddedToken(\":,(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t183: AddedToken(\":-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t184: AddedToken(\":-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t185: AddedToken(\":-S\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t186: AddedToken(\":-C\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t187: AddedToken(\":-r\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t188: AddedToken(\":-t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t189: AddedToken(\":-W\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t190: AddedToken(\"X-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t191: AddedToken(\"l-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t192: AddedToken(\"l:-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t193: AddedToken(\"$-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t194: AddedToken(\":-!\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t195: AddedToken(\":----}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t196: AddedToken(\"=:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t197: AddedToken(\"=:-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t198: AddedToken(\"3:[\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t199: AddedToken(\"8<:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200: AddedToken(\":#)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t201: AddedToken(\"8-#\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t202: AddedToken(\"B-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t203: AddedToken(\"8-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t204: AddedToken(\"|-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t205: AddedToken(\"H-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t206: AddedToken(\"]-I\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t207: AddedToken(\"V^J\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t208: AddedToken(\"+-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t209: AddedToken(\"~:-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t210: AddedToken(\"`'\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t211: AddedToken(\"L-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t212: AddedToken(\"BI\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t213: AddedToken(\"O|\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t214: AddedToken(\"^^\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t215: AddedToken(\"ㅜㅜ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t216: AddedToken(\"ㅠㅠ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t217: AddedToken(\"ㅡㅡ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t218: AddedToken(\"😠\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t219: AddedToken(\"👿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t220: AddedToken(\"😧\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t221: AddedToken(\"😰\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t222: AddedToken(\"😲\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t223: AddedToken(\"😁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t224: AddedToken(\"🐻\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t225: AddedToken(\"🐱\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t226: AddedToken(\"😹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t227: AddedToken(\"😼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t228: AddedToken(\"🤡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t229: AddedToken(\"🥶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t230: AddedToken(\"😖\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t231: AddedToken(\"😕\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t232: AddedToken(\"🐮\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t233: AddedToken(\"🤠\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t234: AddedToken(\"😿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t235: AddedToken(\"😢\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t236: AddedToken(\"😞\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t237: AddedToken(\"😵\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t238: AddedToken(\"🐶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t239: AddedToken(\"😓\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t240: AddedToken(\"🐲\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t241: AddedToken(\"🤤\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t242: AddedToken(\"😑\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t243: AddedToken(\"😘\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t244: AddedToken(\"😋\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t245: AddedToken(\"😱\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t246: AddedToken(\"🤮\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t247: AddedToken(\"🤭\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t248: AddedToken(\"🤕\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t249: AddedToken(\"😷\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t250: AddedToken(\"🧐\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t251: AddedToken(\"😮\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t252: AddedToken(\"🤨\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t253: AddedToken(\"🙄\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t254: AddedToken(\"😤\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t255: AddedToken(\"🤬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t256: AddedToken(\"😂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t257: AddedToken(\"🤒\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t258: AddedToken(\"😛\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t259: AddedToken(\"😶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t260: AddedToken(\"😨\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t261: AddedToken(\"🌛\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t262: AddedToken(\"😳\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t263: AddedToken(\"🦊\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t264: AddedToken(\"🐸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t265: AddedToken(\"☹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t266: AddedToken(\"☹️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t267: AddedToken(\"😦\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t268: AddedToken(\"🌝\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t269: AddedToken(\"😬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t270: AddedToken(\"😺\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t271: AddedToken(\"😸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t272: AddedToken(\"😀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t273: AddedToken(\"😃\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t274: AddedToken(\"😄\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t275: AddedToken(\"😅\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t276: AddedToken(\"😆\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t277: AddedToken(\"🐹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t278: AddedToken(\"🐴\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t279: AddedToken(\"🥵\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t280: AddedToken(\"🤗\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t281: AddedToken(\"😯\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t282: AddedToken(\"😽\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t283: AddedToken(\"😗\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t284: AddedToken(\"😚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t285: AddedToken(\"😙\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t286: AddedToken(\"🌜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t287: AddedToken(\"🦁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t288: AddedToken(\"😭\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t289: AddedToken(\"🤥\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t290: AddedToken(\"🤦🏿‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t291: AddedToken(\"🤦🏻‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t292: AddedToken(\"🤦🏾‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t293: AddedToken(\"🤦🏼‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t294: AddedToken(\"🤦🏽‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t295: AddedToken(\"🤦‍♂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t296: AddedToken(\"🤦🏿‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t297: AddedToken(\"🤦🏻‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t298: AddedToken(\"🤦🏾‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t299: AddedToken(\"🤦🏼‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t300: AddedToken(\"🤦🏽‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t301: AddedToken(\"🤦‍♂️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t302: AddedToken(\"🤑\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t303: AddedToken(\"🐵\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t304: AddedToken(\"🐭\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t305: AddedToken(\"🤢\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t306: AddedToken(\"🤓\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t307: AddedToken(\"😐\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t308: AddedToken(\"🌚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t309: AddedToken(\"🐼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t310: AddedToken(\"🥳\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t311: AddedToken(\"😔\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t312: AddedToken(\"😣\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t313: AddedToken(\"🤦\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t314: AddedToken(\"🤦🏿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t315: AddedToken(\"🤦🏻\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t316: AddedToken(\"🤦🏾\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t317: AddedToken(\"🤦🏼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t318: AddedToken(\"🤦🏽\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t319: AddedToken(\"🐷\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t320: AddedToken(\"🥺\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t321: AddedToken(\"😾\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t322: AddedToken(\"😡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t323: AddedToken(\"🐰\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t324: AddedToken(\"😌\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t325: AddedToken(\"🤖\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t326: AddedToken(\"😥\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t327: AddedToken(\"🤫\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t328: AddedToken(\"😴\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t329: AddedToken(\"😪\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t330: AddedToken(\"🙁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t331: AddedToken(\"🙂\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t332: AddedToken(\"😻\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t333: AddedToken(\"☺\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t334: AddedToken(\"☺️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t335: AddedToken(\"🥰\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t336: AddedToken(\"😇\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t337: AddedToken(\"😍\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t338: AddedToken(\"😈\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t339: AddedToken(\"😊\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t340: AddedToken(\"😎\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t341: AddedToken(\"😏\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t342: AddedToken(\"🤧\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t343: AddedToken(\"😝\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t344: AddedToken(\"🌞\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t345: AddedToken(\"🤔\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t346: AddedToken(\"🐯\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t347: AddedToken(\"😫\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t348: AddedToken(\"😒\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t349: AddedToken(\"🦄\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t350: AddedToken(\"🙃\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t351: AddedToken(\"🙀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t352: AddedToken(\"😩\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t353: AddedToken(\"🌬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t354: AddedToken(\"🌬️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t355: AddedToken(\"😉\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t356: AddedToken(\"😜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t357: AddedToken(\"🐺\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t358: AddedToken(\"🤦🏿‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t359: AddedToken(\"🤦🏻‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t360: AddedToken(\"🤦🏾‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t361: AddedToken(\"🤦🏼‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t362: AddedToken(\"🤦🏽‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t363: AddedToken(\"🤦‍♀\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t364: AddedToken(\"🤦🏿‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t365: AddedToken(\"🤦🏻‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t366: AddedToken(\"🤦🏾‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t367: AddedToken(\"🤦🏼‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t368: AddedToken(\"🤦🏽‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t369: AddedToken(\"🤦‍♀️\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t370: AddedToken(\"🥴\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t371: AddedToken(\"😟\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t372: AddedToken(\"🥱\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t373: AddedToken(\"🤪\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t374: AddedToken(\"🤐\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델과 토크나이저를 불러오기\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x5Ll_NSPScah"
   },
   "outputs": [],
   "source": [
    "# 모델 인퍼런스 단계에서 사용할 prompt 딕셔너리 템플릿과 SFT 데이터셋 클래스를 정의\n",
    "\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RixYkHHvSoK5"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Met4lInaUJNM",
    "outputId": "1a8c792f-9e01-4d8c-9fe7-b2dbabeff28e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "# SFT_dataset 클래스를 사용해 훈련셋을 만들고 data collator 인스턴스를 만들기\n",
    "train_dataset = SFT_dataset(data_path_1_SFT='KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rXC9_RjVUnc9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def verify_tokenization(dataset, tokenizer):\n",
    "    print(\"## Tokenization Verification Start ##\\n\")\n",
    "\n",
    "    # 1. 첫 번째 데이터 샘플 가져오기\n",
    "    # dataset[0]은 {'input_ids': tensor, 'labels': tensor} 형태입니다.\n",
    "    sample = dataset[0]\n",
    "    input_ids = sample['input_ids']\n",
    "    labels = sample['labels']\n",
    "\n",
    "    # 2. input_ids 디코딩 (전체 문장 확인)\n",
    "    # input_ids는 [Instruction + Response]가 모두 포함된 상태입니다.\n",
    "    decoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    print(f\"1. [Input_ids] Full Text (Instruction + Response):\\n{'-'*40}\")\n",
    "    print(decoded_input)\n",
    "    print(f\"{'-'*40}\\n\")\n",
    "\n",
    "    # 3. labels 디코딩 (학습 대상 확인)\n",
    "    # labels에서 -100은 Loss 계산에서 제외되는 부분(Instruction)입니다.\n",
    "    # -100이 아닌 부분(Response)만 추출하여 디코딩합니다.\n",
    "    valid_labels = [token_id for token_id in labels if token_id != -100]\n",
    "    decoded_labels = tokenizer.decode(valid_labels, skip_special_tokens=False)\n",
    "\n",
    "    print(f\"2. [Labels] Training Target (Response Only):\\n{'-'*40}\")\n",
    "    print(decoded_labels)\n",
    "    print(f\"{'-'*40}\\n\")\n",
    "\n",
    "    # 4. 토큰별 매핑 확인 (선택 사항: 마스킹 위치 시각화)\n",
    "    print(\"3. [Detailed Mapping] Token vs Label Masking (First 20 tokens):\")\n",
    "    for i, (inp, lbl) in enumerate(zip(input_ids[:20], labels[:20])):\n",
    "        inp_token = tokenizer.decode([inp])\n",
    "        lbl_status = \"MASKED (-100)\" if lbl == -100 else tokenizer.decode([lbl])\n",
    "        print(f\"Idx {i:02d} | Input: {inp_token:<10} | Label: {lbl_status}\")\n",
    "\n",
    "    print(\"\\n## Verification Done ##\")\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "# 데이터셋 로드 (가정)\n",
    "# train_dataset = SFT_dataset(data_path_1_SFT='your_data.json', tokenizer=tokenizer)\n",
    "\n",
    "# 함수 실행\n",
    "# verify_tokenization(train_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Xql8l_n7Vayl"
   },
   "outputs": [],
   "source": [
    "# 훈련을 위한 마지막 단계로 Training arguments를 사용해 trainer 클래스를 정의\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "kEOv3DQOXL2w",
    "outputId": "d0f0ff18-4ea0-4f45-b0da-0588d156d656"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m7777ggo\u001b[0m (\u001b[33m7777ggo-jeju-national-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251205_051149-w90hzma6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/7777ggo-jeju-national-university/huggingface/runs/w90hzma6' target=\"_blank\">wild-blaze-2</a></strong> to <a href='https://wandb.ai/7777ggo-jeju-national-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/7777ggo-jeju-national-university/huggingface' target=\"_blank\">https://wandb.ai/7777ggo-jeju-national-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/7777ggo-jeju-national-university/huggingface/runs/w90hzma6' target=\"_blank\">https://wandb.ai/7777ggo-jeju-national-university/huggingface/runs/w90hzma6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.684800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SFT 훈련을 진행\n",
    "trainer.train()\n",
    "model.save_pretrained('models/output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwkqbhOyXXRj",
    "outputId": "5b91630f-503b-4c76-e59e-4048a38772dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 고기를 먹을 수 없습니다. 하지만 일반적으로 불고기용 고기는 건강에 좋아서 많은 사람들이 즐겨 먹는 음식 중 하나입니다. 그러나 일부 식당에서는 불고기용 고기를 판매하지 않습니다. 따라서 해당 식당의 공식 홈페이지나 전화로 문의하시는 것이 좋을 것 같습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 41대 부통령직을 수행했습니다.』에는 \"리처드 닉슨\"이라는 인물이 등장합니다.)에서는 리처드 닉슨이 47대 부통령직을 맡았던 년도를 알 수 없습니다.>에서는 리처드 닉슨이 46대 부통령직을 맡은 년도가 명시되지 않았습니다.)에서도 리처드 닉슨이 48대\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 시카고에 대한 정보를 가지고 있지 않습니다. 하지만 시카고는 미국 캘리포니아주 로스앤젤레스에 위치한 도시입니다. 시카고는 미국의 주요도시 중 하나이며, 많은 사람들이 살고 있으며, 다양한 문화와 예술이 공존하고 있습니다.湖)는 시카고에서 가장 유명한 관광지 중 하나입니다.湖는 시카고에서\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 미세먼지 여부를 판단할 수 없습니다. 하지만 미세먼지 농도가 높은 날에는 실외 활동을 자제하는 것이 좋습니다. 또한, 외출 후에는 반드시 마스크를 착용하고 손세정제를 사용하는 것이 좋습니다. 따라서 미세먼지가 심한 날에는 마스크를 꼭 착용해야\n"
     ]
    }
   ],
   "source": [
    "# 이제 문장 생성 능력을 확인하기 위해 빠르게 허깅페이스의 pipleline 클래스를 사용하여 generator를 만들어보겠습니다.\n",
    "\n",
    "generator = transformers.pipeline('text-generation', model='models/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(\n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)\n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4pXEo7YYnI_"
   },
   "source": [
    "4. Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AmdA--2BYp49"
   },
   "outputs": [],
   "source": [
    "# 메모리 관리를 위해 캐시를 비우기\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gwxVaq3afwvu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "oK0vGVTNZEye"
   },
   "outputs": [],
   "source": [
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from chatgpt.trainer.rm import RewardModelTrainer\n",
    "\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pVE0-RdZX1j"
   },
   "source": [
    "Reward model을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "d0GxR25VZZFx"
   },
   "outputs": [],
   "source": [
    "# GPTRM_custom 이라는 이름으로 클래스를 선언\n",
    "\n",
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4ybVz1DhbZ_Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdL64LbUbu2D"
   },
   "source": [
    "# 모델과 토크나이저 불러오기\n",
    "\n",
    "# with구문의 NaiveStrategy()는 chatgpt/trainer/strategies 폴더의 base 모듈에서 정의된 Strategy클래스를 상속한 NaiveStrategy클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PWPPmIo6bumH"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04lDwTFKcB1k",
    "outputId": "c516f9f7-dd6f-4428-f476-b2bb8dc3666e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "# RM을 훈련시킬 때 사용할 ranking dataset\n",
    "with open('KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "mYT_Q_CQcXmh"
   },
   "outputs": [],
   "source": [
    "class PairWiseLoss(nn.Module):\n",
    "\n",
    "    def forward(self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor) -> torch.Tensor:\n",
    "        probs = torch.sigmoid(chosen_reward - reject_reward)\n",
    "        log_probs = torch.log(probs)\n",
    "        loss = -log_probs.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atSp5a7PcXPA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cbuI8y7biI-a"
   },
   "outputs": [],
   "source": [
    "total_data_ranking2chosen = []\n",
    "\n",
    "for tmp in list_data_dict:\n",
    "     prompt = tmp['prompt']\n",
    "     ranking = tmp['ranking']\n",
    "\n",
    "     for index in range(1, len(ranking)):\n",
    "         n = ranking[0]\n",
    "         m = ranking[index]\n",
    "\n",
    "\n",
    "         data = {\n",
    "             'prompt': prompt,\n",
    "             'chosen': tmp['completion_{}'.format(n)],\n",
    "             'rejected': tmp['completion_{}'.format(m)]\n",
    "         }\n",
    "\n",
    "         total_data_ranking2chosen.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RAiPGpOiJiC",
    "outputId": "8666f156-ec28-4af1-a53c-ace07b5c48fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '멋있게 잊어 주자', 'chosen': '가끔은 일어나서 눈 앞의 것들을 확실하게 정리하는 것도 좋을 때가 있죠. 그렇게 해서 지우는 것이 더 나은 경우도 있으니까요. 그리고 그렇게 해서 잊어버리면 조금 더 나은 상황으로 다가갈 수 있을 거라 생각합니다. 그러니 마음을 비워놓고 새로운 시작을 해보세요. 더 나은 날들이 오길 바랄게요!', 'rejected': '멋있다 공개 개량\\n\\n잊어 개량\\n\\n주자 개량\\n\\n멋있다 공개 개량\\n\\n잊어 개량\\n\\n주자 개량'}\n"
     ]
    }
   ],
   "source": [
    "# ranking dataset을 shuffle한 후 훈련셋을 만들\n",
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "24935959b22245f796b18a899907fd50",
      "3b101f448c0946db91f1b90d02e418b2",
      "30b9f1be12af4f1d8e2ede7964f36fd5",
      "0723fd4e3f1c408b936ff5863a0c6143",
      "9bb04948bc0f4ebf9a2822913389a26f",
      "db1a60166372467594cefa0a1dcf7607",
      "c5b8744fa37f44a8958dca9e3be923ad",
      "598fc31b289b448b8aef00ede79a41b2",
      "e97ace3e53884202a85b295bdd8bcb39",
      "8eafaf7992004c35a0a69e0b1474f5cc",
      "d14ca06bf8db40dcb97a1758a413480b",
      "846e02b8870845c2bd9cc3530f6393b1",
      "40682afc0a524900bd406fb6f63bf356",
      "5e19cb672dd04e14a12be11597f5eb9a",
      "bb76f7cdbc194cdbb948f7e618d27433",
      "e901e35d78cd4971826d37045897d4a0",
      "86c10111ceb348cd90e2b74fc0ae62a7",
      "92e889204aba40bab5028b7670ef6c37",
      "a2470356eb004b7a8643d819262f07a7",
      "4d0c412f0f954c1ebf90aee3e44fde82",
      "635ddac3e64f40918f23b8370e44111d",
      "44377e80fb364395b0bf02567e283a3f"
     ]
    },
    "id": "OYiECv7ziLq6",
    "outputId": "f8eb6b54-fa93-4ec8-e96c-0ae8fdbe26a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24935959b22245f796b18a899907fd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846e02b8870845c2bd9cc3530f6393b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000]\n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8yH5J2jiREK",
    "outputId": "649eff32-db59-4a42-e873-973bd84daba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "가방 같은 것도 수선해줘요?\n",
      "######################################################################\n",
      "## chosen ##\n",
      "네, 가방도 수선이 가능합니다. 다만 사용하고 있는 가방의 종류와 손상 정도에 따라 수선 방법과 비용이 달라질 수 있습니다. 수선 전에는 꼭 전문가의 상담을 받아보시는 것이 좋습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "다행히 가방을 수선해 드릴 수 있습니다. 다만 보다 정확한 예상 가격을 알기 위해 약간의 정보가 필요합니다. 먼저 가방에 대한 정보를 알려주시면 저희는 가격 협의를 위해 가방을 보고 다시 연락드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "f3UVXv4aiUYw"
   },
   "outputs": [],
   "source": [
    "# rm 학습\n",
    "\n",
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=torch.optim.Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDDcUutsiYii",
    "outputId": "63bfa56a-9142-41c4-8821-8096e253b11a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:32,  1.09s/it]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:32,  1.09s/it, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:00,  1.37it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<03:00,  1.37it/s, loss=0.295]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:18,  1.25it/s, loss=0.295]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:18,  1.25it/s, loss=0.055]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:26,  1.19it/s, loss=0.055]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:26,  1.19it/s, loss=0.0653]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.0653]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.126] \u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:32,  1.15it/s, loss=0.897]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:34,  1.14it/s, loss=0.897]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:34,  1.14it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:35,  1.13it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:35,  1.13it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:35,  1.12it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:35,  1.12it/s, loss=1.1]  \u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:35,  1.11it/s, loss=1.1]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:35,  1.11it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:35,  1.11it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:35,  1.11it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:35,  1.10it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:35,  1.10it/s, loss=0.376]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:35,  1.10it/s, loss=0.376]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:35,  1.10it/s, loss=0.351]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:35,  1.09it/s, loss=0.351]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:35,  1.09it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:35,  1.09it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:35,  1.09it/s, loss=0.446]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:34,  1.09it/s, loss=0.446]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:34,  1.09it/s, loss=0.763]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:34,  1.09it/s, loss=0.763]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:34,  1.09it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:33,  1.09it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:33,  1.09it/s, loss=0.165]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:33,  1.08it/s, loss=0.165]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:33,  1.08it/s, loss=0.0147]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:33,  1.08it/s, loss=0.0147]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:18<03:33,  1.08it/s, loss=0.285] \u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:32,  1.08it/s, loss=0.285]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:19<03:32,  1.08it/s, loss=1.42] \u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:31,  1.08it/s, loss=1.42]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:20<03:31,  1.08it/s, loss=0.171]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:30,  1.08it/s, loss=0.171]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:21<03:30,  1.08it/s, loss=0.0774]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:30,  1.08it/s, loss=0.0774]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:22<03:30,  1.08it/s, loss=0.622] \u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:29,  1.07it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:23<03:29,  1.07it/s, loss=0.459]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:23<03:28,  1.07it/s, loss=0.459]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:24<03:28,  1.07it/s, loss=0.17] \u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:27,  1.07it/s, loss=0.17]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:27,  1.07it/s, loss=0.0351]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:26,  1.08it/s, loss=0.0351]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:26,  1.08it/s, loss=0.0262]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:26<03:25,  1.08it/s, loss=0.0262]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:26<03:25,  1.08it/s, loss=0.233] \u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:27<03:23,  1.08it/s, loss=0.233]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:27<03:23,  1.08it/s, loss=0.00471]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:28<03:22,  1.08it/s, loss=0.00471]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:28<03:22,  1.08it/s, loss=0.0395] \u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:29<03:21,  1.08it/s, loss=0.0395]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:29<03:21,  1.08it/s, loss=0.108] \u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:30<03:19,  1.09it/s, loss=0.108]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:30<03:19,  1.09it/s, loss=0.174]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:18,  1.09it/s, loss=0.174]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:31<03:18,  1.09it/s, loss=0.0253]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:31<03:17,  1.09it/s, loss=0.0253]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:32<03:17,  1.09it/s, loss=0.762] \u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:32<03:15,  1.09it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:33<03:15,  1.09it/s, loss=0.00337]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:33<03:14,  1.10it/s, loss=0.00337]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:34<03:14,  1.10it/s, loss=0.469]  \u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:34<03:12,  1.10it/s, loss=0.469]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:35<03:12,  1.10it/s, loss=0.0872]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:35<03:11,  1.10it/s, loss=0.0872]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:35<03:11,  1.10it/s, loss=0.00283]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:36<03:09,  1.11it/s, loss=0.00283]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:36<03:09,  1.11it/s, loss=0.0339] \u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:37<03:08,  1.11it/s, loss=0.0339]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:37<03:08,  1.11it/s, loss=0.245] \u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:38<03:07,  1.11it/s, loss=0.245]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:38<03:07,  1.11it/s, loss=0.0545]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:39<03:06,  1.11it/s, loss=0.0545]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:39<03:06,  1.11it/s, loss=0.000939]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:39<03:05,  1.11it/s, loss=0.000939]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:40<03:05,  1.11it/s, loss=0.0323]  \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:40<03:04,  1.11it/s, loss=0.0323]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:41<03:04,  1.11it/s, loss=0.0724]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:41<03:03,  1.11it/s, loss=0.0724]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:42<03:03,  1.11it/s, loss=0.11]  \u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:42<03:02,  1.11it/s, loss=0.11]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:43<03:02,  1.11it/s, loss=0.00136]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:43<03:01,  1.11it/s, loss=0.00136]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:44<03:01,  1.11it/s, loss=0.0349] \u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:44<03:00,  1.12it/s, loss=0.0349]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:44<03:00,  1.12it/s, loss=0.0934]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:45<02:59,  1.12it/s, loss=0.0934]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:45<02:59,  1.12it/s, loss=0.0515]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:46<02:57,  1.12it/s, loss=0.0515]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:46<02:57,  1.12it/s, loss=0.0144]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:47<02:56,  1.12it/s, loss=0.0144]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:47<02:56,  1.12it/s, loss=0.94]  \u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:48<02:56,  1.12it/s, loss=0.94]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:48<02:56,  1.12it/s, loss=0.00198]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:48<02:54,  1.12it/s, loss=0.00198]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:49<02:54,  1.12it/s, loss=0.00294]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:49<02:52,  1.13it/s, loss=0.00294]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:50<02:52,  1.13it/s, loss=0.000188]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:50<02:51,  1.13it/s, loss=0.000188]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:51<02:51,  1.13it/s, loss=0.0321]  \u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:51<02:51,  1.13it/s, loss=0.0321]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:52<02:51,  1.13it/s, loss=0.261] \u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:49,  1.13it/s, loss=0.261]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:49,  1.13it/s, loss=0.232]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:49,  1.13it/s, loss=0.232]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:49,  1.13it/s, loss=0.0072]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:54<02:48,  1.13it/s, loss=0.0072]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:54<02:48,  1.13it/s, loss=0.0829]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:55<02:47,  1.13it/s, loss=0.0829]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:55<02:47,  1.13it/s, loss=0.0135]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:55<02:46,  1.13it/s, loss=0.0135]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:56<02:46,  1.13it/s, loss=0.252] \u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:56<02:45,  1.13it/s, loss=0.252]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:57<02:45,  1.13it/s, loss=2.09e-6]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:57<02:44,  1.13it/s, loss=2.09e-6]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:58<02:44,  1.13it/s, loss=0.0565] \u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:58<02:44,  1.13it/s, loss=0.0565]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:59<02:44,  1.13it/s, loss=0.0923]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:43,  1.13it/s, loss=0.0923]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:43,  1.13it/s, loss=0.217] \u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:42,  1.13it/s, loss=0.217]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:42,  1.13it/s, loss=0.0564]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:41,  1.13it/s, loss=0.0564]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:41,  1.13it/s, loss=0.423] \u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:02<02:39,  1.13it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:02<02:39,  1.13it/s, loss=0.00211]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:03<02:38,  1.14it/s, loss=0.00211]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:03<02:38,  1.14it/s, loss=0.000579]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:03<02:36,  1.14it/s, loss=0.000579]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:04<02:36,  1.14it/s, loss=1.54]    \u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:04<02:36,  1.14it/s, loss=1.54]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:05<02:36,  1.14it/s, loss=0.0177]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:05<02:35,  1.14it/s, loss=0.0177]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:06<02:35,  1.14it/s, loss=0.133] \u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:06<02:35,  1.13it/s, loss=0.133]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:07<02:35,  1.13it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:34,  1.13it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:34,  1.13it/s, loss=0.149]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:33,  1.13it/s, loss=0.149]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:33,  1.13it/s, loss=0.156]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:09<02:33,  1.13it/s, loss=0.156]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:09<02:33,  1.13it/s, loss=0.0985]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:10<02:32,  1.13it/s, loss=0.0985]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:10<02:32,  1.13it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:11<02:31,  1.13it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:11<02:31,  1.13it/s, loss=0.0208]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:11<02:30,  1.13it/s, loss=0.0208]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:12<02:30,  1.13it/s, loss=0.179] \u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:12<02:29,  1.13it/s, loss=0.179]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:13<02:29,  1.13it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:13<02:29,  1.13it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:14<02:29,  1.13it/s, loss=0.0842]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:14<02:28,  1.13it/s, loss=0.0842]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:15<02:28,  1.13it/s, loss=0.424] \u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:15<02:27,  1.13it/s, loss=0.424]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:15<02:27,  1.13it/s, loss=0.213]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:16<02:26,  1.13it/s, loss=0.213]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:16<02:26,  1.13it/s, loss=0.094]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:17<02:25,  1.13it/s, loss=0.094]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:17<02:25,  1.13it/s, loss=0.0314]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:18<02:24,  1.13it/s, loss=0.0314]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:18<02:24,  1.13it/s, loss=0.0215]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:19<02:24,  1.12it/s, loss=0.0215]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:19<02:24,  1.12it/s, loss=0.428] \u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:19<02:23,  1.12it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:20<02:23,  1.12it/s, loss=1.02] \u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:20<02:22,  1.12it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:21<02:22,  1.12it/s, loss=0.0113]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:21<02:21,  1.12it/s, loss=0.0113]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:22<02:21,  1.12it/s, loss=0.213] \u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:22<02:20,  1.12it/s, loss=0.213]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:23<02:20,  1.12it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:23<02:19,  1.12it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:23<02:19,  1.12it/s, loss=0.0119]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:24<02:18,  1.12it/s, loss=0.0119]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:24<02:18,  1.12it/s, loss=0.0685]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:25<02:18,  1.12it/s, loss=0.0685]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:25<02:18,  1.12it/s, loss=0.251] \u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:26<02:17,  1.12it/s, loss=0.251]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:26<02:17,  1.12it/s, loss=0.0669]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:27<02:16,  1.12it/s, loss=0.0669]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:27<02:16,  1.12it/s, loss=0.718] \u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:27<02:15,  1.12it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:28<02:15,  1.12it/s, loss=0.147]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:28<02:15,  1.12it/s, loss=0.147]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:29<02:15,  1.12it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:29<02:14,  1.12it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:30<02:14,  1.12it/s, loss=0.0435]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:30<02:13,  1.12it/s, loss=0.0435]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:31<02:13,  1.12it/s, loss=0.101] \u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:31<02:12,  1.12it/s, loss=0.101]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:31<02:12,  1.12it/s, loss=0.422]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:32<02:11,  1.11it/s, loss=0.422]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:32<02:11,  1.11it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:33<02:11,  1.11it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:33<02:11,  1.11it/s, loss=0.11] \u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:34<02:10,  1.11it/s, loss=0.11]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:34<02:10,  1.11it/s, loss=0.284]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:35<02:09,  1.11it/s, loss=0.284]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:35<02:09,  1.11it/s, loss=0.0385]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:36<02:08,  1.11it/s, loss=0.0385]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:36<02:08,  1.11it/s, loss=0.108] \u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:36<02:07,  1.11it/s, loss=0.108]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:37<02:07,  1.11it/s, loss=0.0943]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:37<02:06,  1.11it/s, loss=0.0943]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:38<02:06,  1.11it/s, loss=0.0939]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:38<02:05,  1.11it/s, loss=0.0939]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:39<02:05,  1.11it/s, loss=0.0359]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:39<02:05,  1.11it/s, loss=0.0359]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:40<02:05,  1.11it/s, loss=0.0188]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:40<02:04,  1.11it/s, loss=0.0188]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:40<02:04,  1.11it/s, loss=0.0444]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:41<02:03,  1.11it/s, loss=0.0444]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:41<02:03,  1.11it/s, loss=0.00973]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:42<02:02,  1.11it/s, loss=0.00973]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:42<02:02,  1.11it/s, loss=0.0786] \u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:43<02:01,  1.11it/s, loss=0.0786]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:43<02:01,  1.11it/s, loss=0.109] \u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:44<02:00,  1.11it/s, loss=0.109]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:44<02:00,  1.11it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:45<01:59,  1.11it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:45<01:59,  1.11it/s, loss=0.0016] \u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:45<01:58,  1.11it/s, loss=0.0016]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:46<01:58,  1.11it/s, loss=0.0569]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:46<01:58,  1.11it/s, loss=0.0569]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:47<01:58,  1.11it/s, loss=0.000416]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:47<01:57,  1.11it/s, loss=0.000416]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:48<01:57,  1.11it/s, loss=0.00578] \u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:48<01:56,  1.11it/s, loss=0.00578]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:49<01:56,  1.11it/s, loss=0.104]  \u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:49<01:54,  1.12it/s, loss=0.104]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:49<01:54,  1.12it/s, loss=0.092]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:50<01:52,  1.12it/s, loss=0.092]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:50<01:52,  1.12it/s, loss=0.000361]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:51<01:51,  1.13it/s, loss=0.000361]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:51<01:51,  1.13it/s, loss=0.0019]  \u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:52<01:51,  1.12it/s, loss=0.0019]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:52<01:51,  1.12it/s, loss=0.00485]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:53<01:51,  1.12it/s, loss=0.00485]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:53<01:51,  1.12it/s, loss=3.31e-6]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:53<01:50,  1.11it/s, loss=3.31e-6]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:54<01:50,  1.11it/s, loss=0.0117] \u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:54<01:48,  1.12it/s, loss=0.0117]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:55<01:48,  1.12it/s, loss=0.00505]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:55<01:47,  1.13it/s, loss=0.00505]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:56<01:47,  1.13it/s, loss=0.0925] \u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:56<01:45,  1.14it/s, loss=0.0925]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:56<01:45,  1.14it/s, loss=-0]    \u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:57<01:44,  1.14it/s, loss=-0]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:57<01:44,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:58<01:43,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:58<01:43,  1.14it/s, loss=0.0835]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:59<01:42,  1.14it/s, loss=0.0835]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:59<01:42,  1.14it/s, loss=3.11]  \u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:00<01:42,  1.13it/s, loss=3.11]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:00<01:42,  1.13it/s, loss=0.193]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:01<01:42,  1.12it/s, loss=0.193]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:01<01:42,  1.12it/s, loss=0.046]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:01<01:41,  1.12it/s, loss=0.046]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:02<01:41,  1.12it/s, loss=0.0549]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:02<01:41,  1.12it/s, loss=0.0549]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:03<01:41,  1.12it/s, loss=0.0244]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:03<01:40,  1.11it/s, loss=0.0244]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:04<01:40,  1.11it/s, loss=0.119] \u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:04<01:39,  1.11it/s, loss=0.119]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:05<01:39,  1.11it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:05<01:38,  1.11it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:05<01:38,  1.11it/s, loss=0.31] \u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:06<01:38,  1.11it/s, loss=0.31]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:06<01:38,  1.11it/s, loss=0.32]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:07<01:37,  1.11it/s, loss=0.32]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:07<01:37,  1.11it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:08<01:36,  1.11it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:08<01:36,  1.11it/s, loss=0.245]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:09<01:35,  1.11it/s, loss=0.245]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:09<01:35,  1.11it/s, loss=0.107]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:10<01:34,  1.11it/s, loss=0.107]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:10<01:34,  1.11it/s, loss=0.128]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:10<01:33,  1.11it/s, loss=0.128]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:11<01:33,  1.11it/s, loss=0.0397]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:11<01:32,  1.11it/s, loss=0.0397]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:12<01:32,  1.11it/s, loss=0.0745]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:12<01:31,  1.11it/s, loss=0.0745]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:13<01:31,  1.11it/s, loss=0.021] \u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:13<01:30,  1.11it/s, loss=0.021]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:14<01:30,  1.11it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:14<01:29,  1.11it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:14<01:29,  1.11it/s, loss=0.236]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:15<01:28,  1.11it/s, loss=0.236]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:15<01:28,  1.11it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:16<01:27,  1.12it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:16<01:27,  1.12it/s, loss=0.0134]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:17<01:26,  1.12it/s, loss=0.0134]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:17<01:26,  1.12it/s, loss=0.0657]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:18<01:26,  1.12it/s, loss=0.0657]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:18<01:26,  1.12it/s, loss=0.0995]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:19<01:25,  1.12it/s, loss=0.0995]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:19<01:25,  1.12it/s, loss=0.0647]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:19<01:24,  1.12it/s, loss=0.0647]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:20<01:24,  1.12it/s, loss=0.341] \u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:20<01:23,  1.12it/s, loss=0.341]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:21<01:23,  1.12it/s, loss=0.0502]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:21<01:22,  1.12it/s, loss=0.0502]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:22<01:22,  1.12it/s, loss=0.0424]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:22<01:21,  1.12it/s, loss=0.0424]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:23<01:21,  1.12it/s, loss=0.00313]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:23<01:20,  1.12it/s, loss=0.00313]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:23<01:20,  1.12it/s, loss=0.0036] \u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:24<01:19,  1.12it/s, loss=0.0036]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:24<01:19,  1.12it/s, loss=0.836] \u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:25<01:18,  1.12it/s, loss=0.836]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:25<01:18,  1.12it/s, loss=0.00367]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:26<01:17,  1.12it/s, loss=0.00367]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:26<01:17,  1.12it/s, loss=0.0113] \u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:27<01:16,  1.12it/s, loss=0.0113]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:27<01:16,  1.12it/s, loss=0.0726]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:27<01:15,  1.12it/s, loss=0.0726]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:28<01:15,  1.12it/s, loss=0.0728]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:28<01:15,  1.12it/s, loss=0.0728]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:29<01:15,  1.12it/s, loss=0.00648]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:29<01:14,  1.12it/s, loss=0.00648]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:30<01:14,  1.12it/s, loss=0.0246] \u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:30<01:13,  1.12it/s, loss=0.0246]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:31<01:13,  1.12it/s, loss=0.03]  \u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:31<01:12,  1.12it/s, loss=0.03]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:31<01:12,  1.12it/s, loss=0.49]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:32<01:11,  1.12it/s, loss=0.49]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:32<01:11,  1.12it/s, loss=0.0995]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:33<01:10,  1.12it/s, loss=0.0995]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:33<01:10,  1.12it/s, loss=0.391] \u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:34<01:09,  1.12it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:34<01:09,  1.12it/s, loss=0.161]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:35<01:08,  1.12it/s, loss=0.161]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:35<01:08,  1.12it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:35<01:07,  1.12it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:36<01:07,  1.12it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:36<01:06,  1.12it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:37<01:06,  1.12it/s, loss=0.0549]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:37<01:05,  1.12it/s, loss=0.0549]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:38<01:05,  1.12it/s, loss=0.142] \u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:38<01:04,  1.12it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:39<01:04,  1.12it/s, loss=0.145]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:39<01:04,  1.12it/s, loss=0.145]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:39<01:04,  1.12it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:40<01:03,  1.12it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:40<01:03,  1.12it/s, loss=0.425]  \u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:41<01:02,  1.12it/s, loss=0.425]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:41<01:02,  1.12it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:42<01:01,  1.12it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:42<01:01,  1.12it/s, loss=0.0515]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:43<01:00,  1.12it/s, loss=0.0515]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:43<01:00,  1.12it/s, loss=0.00165]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:44<00:59,  1.12it/s, loss=0.00165]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:44<00:59,  1.12it/s, loss=1.21]   \u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:44<00:58,  1.12it/s, loss=1.21]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:45<00:58,  1.12it/s, loss=0.0689]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:45<00:58,  1.12it/s, loss=0.0689]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:46<00:58,  1.12it/s, loss=0.0896]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:46<00:57,  1.12it/s, loss=0.0896]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:47<00:57,  1.12it/s, loss=0.773] \u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:47<00:56,  1.12it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:48<00:56,  1.12it/s, loss=0.34] \u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:48<00:55,  1.12it/s, loss=0.34]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:48<00:55,  1.12it/s, loss=0.0437]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:49<00:54,  1.12it/s, loss=0.0437]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:49<00:54,  1.12it/s, loss=0.0575]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:50<00:53,  1.12it/s, loss=0.0575]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:50<00:53,  1.12it/s, loss=0.136] \u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:51<00:52,  1.12it/s, loss=0.136]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:51<00:52,  1.12it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:52<00:51,  1.12it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:52<00:51,  1.12it/s, loss=0.172]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:52<00:50,  1.12it/s, loss=0.172]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:53<00:50,  1.12it/s, loss=0.016]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:53<00:50,  1.12it/s, loss=0.016]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:54<00:50,  1.12it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:54<00:49,  1.12it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:55<00:49,  1.12it/s, loss=0.19] \u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:55<00:48,  1.12it/s, loss=0.19]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:56<00:48,  1.12it/s, loss=0.0498]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:56<00:47,  1.11it/s, loss=0.0498]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:56<00:47,  1.11it/s, loss=0.0307]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:57<00:46,  1.12it/s, loss=0.0307]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:57<00:46,  1.12it/s, loss=0.139] \u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:58<00:45,  1.12it/s, loss=0.139]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:58<00:45,  1.12it/s, loss=0.241]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:59<00:44,  1.12it/s, loss=0.241]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:59<00:44,  1.12it/s, loss=0.198]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:00<00:43,  1.11it/s, loss=0.198]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:00<00:43,  1.11it/s, loss=0.161]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:01<00:43,  1.11it/s, loss=0.161]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:01<00:43,  1.11it/s, loss=0.00126]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:01<00:42,  1.11it/s, loss=0.00126]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:02<00:42,  1.11it/s, loss=0.105]  \u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:02<00:41,  1.11it/s, loss=0.105]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:03<00:41,  1.11it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:03<00:40,  1.11it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:04<00:40,  1.11it/s, loss=0.155]  \u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:04<00:39,  1.12it/s, loss=0.155]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:05<00:39,  1.12it/s, loss=0.0279]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:05<00:38,  1.11it/s, loss=0.0279]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:05<00:38,  1.11it/s, loss=0.000327]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:06<00:37,  1.11it/s, loss=0.000327]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:06<00:37,  1.11it/s, loss=0.236]   \u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:07<00:36,  1.11it/s, loss=0.236]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:07<00:36,  1.11it/s, loss=0.000147]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:08<00:35,  1.11it/s, loss=0.000147]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:08<00:35,  1.11it/s, loss=0.0406]  \u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:09<00:35,  1.11it/s, loss=0.0406]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:09<00:35,  1.11it/s, loss=0.0282]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:10<00:34,  1.11it/s, loss=0.0282]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:10<00:34,  1.11it/s, loss=0.0469]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:10<00:33,  1.12it/s, loss=0.0469]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:11<00:33,  1.12it/s, loss=0.000605]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:11<00:32,  1.12it/s, loss=0.000605]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:12<00:32,  1.12it/s, loss=0.26]    \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:12<00:31,  1.12it/s, loss=0.26]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:13<00:31,  1.12it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:13<00:30,  1.12it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:14<00:30,  1.12it/s, loss=0.214]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:14<00:29,  1.12it/s, loss=0.214]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:14<00:29,  1.12it/s, loss=0.246]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:15<00:28,  1.13it/s, loss=0.246]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:15<00:28,  1.13it/s, loss=0.196]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:16<00:27,  1.13it/s, loss=0.196]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:16<00:27,  1.13it/s, loss=0.0473]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:17<00:26,  1.12it/s, loss=0.0473]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:17<00:26,  1.12it/s, loss=0.0717]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:18<00:25,  1.12it/s, loss=0.0717]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:18<00:25,  1.12it/s, loss=0.0358]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:18<00:24,  1.12it/s, loss=0.0358]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:19<00:24,  1.12it/s, loss=0.169] \u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:19<00:23,  1.13it/s, loss=0.169]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:20<00:23,  1.13it/s, loss=0.0765]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:20<00:22,  1.13it/s, loss=0.0765]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:21<00:22,  1.13it/s, loss=0.0105]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:21<00:21,  1.14it/s, loss=0.0105]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:21<00:21,  1.14it/s, loss=0.00184]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:22<00:20,  1.15it/s, loss=0.00184]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:22<00:20,  1.15it/s, loss=0.0889] \u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:23<00:20,  1.14it/s, loss=0.0889]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:23<00:20,  1.14it/s, loss=0.443] \u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:24<00:19,  1.15it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:24<00:19,  1.15it/s, loss=0.00067]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:25<00:18,  1.14it/s, loss=0.00067]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:25<00:18,  1.14it/s, loss=0.0277] \u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:25<00:17,  1.14it/s, loss=0.0277]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:26<00:17,  1.14it/s, loss=0.0656]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:26<00:16,  1.14it/s, loss=0.0656]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:27<00:16,  1.14it/s, loss=0.577] \u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:27<00:15,  1.14it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:28<00:15,  1.14it/s, loss=1.46e-6]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:28<00:14,  1.15it/s, loss=1.46e-6]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:28<00:14,  1.15it/s, loss=0.0162] \u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:29<00:13,  1.14it/s, loss=0.0162]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:29<00:13,  1.14it/s, loss=1.92]  \u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:30<00:13,  1.14it/s, loss=1.92]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:30<00:13,  1.14it/s, loss=0.00698]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:31<00:12,  1.13it/s, loss=0.00698]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:31<00:12,  1.13it/s, loss=0.115]  \u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:32<00:11,  1.13it/s, loss=0.115]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:32<00:11,  1.13it/s, loss=0.117]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:32<00:10,  1.13it/s, loss=0.117]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:33<00:10,  1.13it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:33<00:09,  1.12it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:34<00:09,  1.12it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:34<00:08,  1.12it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:35<00:08,  1.12it/s, loss=0.211]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:35<00:08,  1.12it/s, loss=0.211]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:36<00:08,  1.12it/s, loss=0.0212]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:36<00:07,  1.12it/s, loss=0.0212]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:36<00:07,  1.12it/s, loss=0.234] \u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:37<00:06,  1.12it/s, loss=0.234]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:37<00:06,  1.12it/s, loss=0.0194]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:38<00:05,  1.11it/s, loss=0.0194]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:38<00:05,  1.11it/s, loss=0.00731]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:39<00:04,  1.12it/s, loss=0.00731]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:39<00:04,  1.12it/s, loss=0.458]  \u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:40<00:03,  1.12it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:40<00:03,  1.12it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:41<00:02,  1.11it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:41<00:02,  1.11it/s, loss=0.253]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:41<00:01,  1.11it/s, loss=0.253]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:42<00:01,  1.11it/s, loss=0.74] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:42<00:00,  1.11it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:43<00:00,  1.11it/s, loss=0.00979]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:43<00:00,  1.11it/s, loss=0.00979]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:57<00:00, 237.79s/it]\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:57<00:00,  1.05it/s, loss=0.149, dist_mean=4.76]\n",
      "Train epoch: 100%|██████████| 1/1 [03:57<00:00, 237.80s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('models/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0Nhx3iTiZ_X",
    "outputId": "e1fd60cb-ba51-4643-d199-4513aff02588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: 7.3\n"
     ]
    }
   ],
   "source": [
    "# RM 학습이 잘 되었는지 확인해보기 위해 임의의 문장을 입력한 후 적절한 reward score를 출력하는지 살펴보도록 하겠습니다.\n",
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').cuda()\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kK_K4ZIit_o",
    "outputId": "1a88725c-8c35-491e-bb4d-1132a51ccd0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: 10.0\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTpRalRPixTG",
    "outputId": "4d314b89-f72b-409d-8bd6-5d4155e4f91b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: 10.7\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJSftbrbiy92",
    "outputId": "cc43972a-c374-40f0-f65c-f764a12918a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 10.1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbeQueTYi821"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftsrNpfYi7Jt"
   },
   "source": [
    " PPO 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "N54C9Ozhi8fB"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GZRSFAcDjKYq"
   },
   "outputs": [],
   "source": [
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "C7k6u1tljM8w"
   },
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='models/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='models/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\",\n",
    "        model_max_length=512\n",
    "    )\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tlwz6t6ujMti"
   },
   "outputs": [],
   "source": [
    "actor_optim = torch.optim.Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = torch.optim.Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "7-ZpPTBSjMZO"
   },
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Zhc8KQy_jQxq"
   },
   "outputs": [],
   "source": [
    "with open('KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wvsx994ljR9Q",
    "outputId": "8457d02d-0648-4752-e909-7f90c2214ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdxIW0LljTLD",
    "outputId": "f6e55f0a-74bd-4474-a7ac-b6674a523c03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "GtxJyNL8jVF4"
   },
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,\n",
    "                     train_batch_size=8,\n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-_ILmhylMvx",
    "outputId": "873db518-1c36-409b-fa4f-953eed05d07c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.09s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00409]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s, actor_loss=0, critic_loss=0.00409]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.77it/s, actor_loss=0, critic_loss=0.295]  \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.295]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=0, critic_loss=0.00929]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0, critic_loss=0.00929]\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:19<00:00,  6.65s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.18s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-0.367, critic_loss=0.177]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-0.367, critic_loss=0.177]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-0.378, critic_loss=0.144]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-0.378, critic_loss=0.144]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s, actor_loss=-0.397, critic_loss=0.0452]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s, actor_loss=-0.397, critic_loss=0.0452]\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:20<00:00,  6.68s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.14s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.127, critic_loss=0.016]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=0.127, critic_loss=0.016]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=0.118, critic_loss=0.0862]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.118, critic_loss=0.0862]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=0.125, critic_loss=0.0923]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=0.125, critic_loss=0.0923]\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:20<00:00,  6.68s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.20s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.261, critic_loss=0.0672]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.261, critic_loss=0.0672]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.25, critic_loss=0.00883]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.25, critic_loss=0.00883]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.241, critic_loss=0.0158]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.241, critic_loss=0.0158]\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:20<00:00,  6.67s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.03s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-0.178, critic_loss=0.0451]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-0.178, critic_loss=0.0451]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-0.233, critic_loss=0.0803]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-0.233, critic_loss=0.0803]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-0.217, critic_loss=0.0521]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-0.217, critic_loss=0.0521]\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:19<00:00,  6.64s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.09s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-0.051, critic_loss=0.0104]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.83it/s, actor_loss=-0.051, critic_loss=0.0104]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.83it/s, actor_loss=-0.0684, critic_loss=0.017]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=-0.0684, critic_loss=0.017]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=-0.0788, critic_loss=0.0217]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s, actor_loss=-0.0788, critic_loss=0.0217]\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:19<00:00,  6.66s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.11s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.199, critic_loss=0.0534]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.199, critic_loss=0.0534]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.209, critic_loss=0.0411]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=0.209, critic_loss=0.0411]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.84it/s, actor_loss=0.156, critic_loss=0.00222]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=0.156, critic_loss=0.00222]\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:20<00:00,  6.68s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.09s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-0.0288, critic_loss=0.00905]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-0.0288, critic_loss=0.00905]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-0.0248, critic_loss=0.0116] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-0.0248, critic_loss=0.0116]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-0.0431, critic_loss=0.0214]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-0.0431, critic_loss=0.0214]\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:19<00:00,  6.61s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.46s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-0.104, critic_loss=0.0124]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.90it/s, actor_loss=-0.104, critic_loss=0.0124]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.90it/s, actor_loss=-0.111, critic_loss=0.0048]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-0.111, critic_loss=0.0048]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-0.119, critic_loss=0.00184]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-0.119, critic_loss=0.00184]\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:18<00:00,  6.27s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.11s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0716, critic_loss=0.0125]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.0716, critic_loss=0.0125]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.0892, critic_loss=0.0133]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0892, critic_loss=0.0133]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0944, critic_loss=0.0182]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0944, critic_loss=0.0182]\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:18<00:00,  6.11s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt,\n",
    "            num_episodes=10,\n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "actor.model.save_pretrained('models/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppTWgwsHjW5o",
    "outputId": "2d5dc48c-9f9f-4c10-f818-3f279762a1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇으로써 음식에 대한 정보를 알기 때문에 고기용 고기를 제공하는지에 대한 확신이 있습니다.\\n\\n\\n그러나 질문하신 질문에 대해선 질문하신 내용이 도움이 되지 않습니다. \\n\\n답변에 대해서는 관련 정보나 문맥을 제공해드리겠습니다. \\n\\n하지만 이에 대해선 질문이 적절하지 않은 경우가 있으므로, 정확한 답변을 얻으실 필요가 있습니다. \\n\\n하지만 질문하신 내용에 대해선 더 구체적으로 말씀해 주시면, 답변드릴 수 있을 것 같습니다. vascular dance service mean, but to the general informative details and assistant myth of specific curry. prisonal approachers to provide my fish. \\n\\n저는 인공지능 챗봇이며, 실제 고기용을 제공하는 것은 아니기 때문에 어떤 질문에 대한 답변을 드릴 수는 없습니다. Please provide my curry and\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨이 43대 부통령직을 수행한 년도는 2016년입니다. 참조할 수 있는 정보가 없기 때문에, 정확한 연도를 제공할 수 없습니다. 참조할 수 있는 정보는 현재까지도 제공되지 않기 때문입니다. 참조할 수 있는 정보는 리처드 닉슨이 부통령직을 수행했다는 사실, 부통령직의 정확한 연도, 부통령직의 직위를 수행했다는 것을 알 수 있습니다. 참조할 수 있는 정보는 대통령 공식 홈페이지나 대통령 공식 홈페이지 등에서 확인하실 수 있습니다. 언급된 경우, 정확한 답변을 얻으시려면 좀 더 구체적인 정보를 알려주시면 더욱 정확한 답변을 제공해드리겠습니다. 언급된 경우, 부통령직을 맡은 것이라는 점을 미리 충분히 설명해주신다면, 더 나은 답변을 드리기 좋을 것입니다. 참고할 수 있는 정보는 제공된다면 더 정확한 답변을 제공해드릴 수 있습니다. 참조할 수 있는 정보는 제공된 경우에 따라 다르겠지만, 일반적으로 질문하시는 내용이 있으면 답변해드릴 수 있습니다. 언급된 경우, 리처드 닉슨이 부통령직을 수행한 것으로 언급된다면, 어떤 연도를 말하는 것이 가능할 수도 있습니다. 언급하는 연도의 경우, 더 자세한\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 버지니아주 앤트워프에 위치한 미국 시카고 시내 고속도로 중 하나로 시카고를 지나고 있습니다. 섐페인 공항은 시카고 시내에서 휴스턴에 접근할 수 있는 도시입니다. 明題銀河(명례銀河) 국제공항은 시카고 시내에서 휴스턴까지 갈 수 있습니다.命際銀河(鳴題銀河) 국제공항은 미국 버지니아주 내륙으로 출발합니다.明際銀河(명례銀河) 국제공항은 시카고를 거쳐 뉴욕까지 간다고 합니다.明際銀河 국제공항은 휴스턴에 접근하거나 휴스턴에 접근할 수 있는 도시입니다. 立啓銀河(立啓)와 立啓銀河(立啓銀河) 국제공항은 워싱턴에 이르는 고속도로 중 하나로, 콜로라도주 디트로이트까지 연결되어 있습니다.明際銀河국제공항은 시카고 시내에서 휴스턴까지는 고속도로 중 하나입니다.明際銀河(立啓銀河銀河) 국제공항은 뉴욕에 도달할 수 있습니다. 立啓銀河(立啓銀河)는 워싱턴에 도착하는 데에 중요한 공항입니다. 立\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'제가 AI 챗봇이므로, 미세먼지에 대해 구체적인 정보를 알 수 없습니다. 미세먼지가 발생할 수 있는 상황과 관련된 정보를 가지고 있다면, 해당 지역의 공청회, 언론 등을 활용하여 해당 공청회 또는 정보를 제공해 주시기 바랍니다.\\n\\n미세먼지가 발생한다면 저는 그것을 파악하지 못하고 있으며, 이에 대한 대처 방법으로는 다음과 같은 것들이 있을 수 있습니다.\\n\\n1. 마스크 사용: 공기 중에 미세먼지가 있는지 확인하고 대기 중 미세먼지 제거기를 사용하여 대기 중 미세먼지를 제거합니다. 그리고 적절한 마스크를 선택하여 사용하는 것이 중요합니다.\\n\\n2. 공기청소: 미세먼지를 깨끗하게 청소한 후 미세먼지를 제거하면 대기 중의 미세먼지는 줄어들지만, 미세먼지가 많이 발생하는 경우에는 청소하기도 어렵습니다.\\n\\n3. 외출 시 미세먼지 농도가 높은 지역으로 가거나 집안 청소하기. 예를 들어, 집 안에서 미세먼지를 제거하고 그 지역으로 가려는 것은 나쁜 방법일 수 있습니다.\\n\\n4. 야외활동을 자제하는 것이 중요합니다. 미세먼지가 많은 지역은 실외활동을 자주하지 않지만, 실내활동을\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text, model):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?',\n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qqe0FSBIjdOs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed: Removed 'widgets' from metadata.\n",
      "Done! Try opening the notebook now.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace this with your actual notebook filename\n",
    "notebook_path = \"Untitled10.ipynb\"\n",
    "\n",
    "# 1. Read the notebook\n",
    "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Remove the offending widget metadata\n",
    "if 'metadata' in data and 'widgets' in data['metadata']:\n",
    "    del data['metadata']['widgets']\n",
    "    print(\"Fixed: Removed 'widgets' from metadata.\")\n",
    "else:\n",
    "    print(\"No 'widgets' key found in metadata. The file might already be clean.\")\n",
    "\n",
    "# 3. Save the fixed notebook\n",
    "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=1)\n",
    "\n",
    "print(\"Done! Try opening the notebook now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "008527e6c5804d8c96d5b9184007f024": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0723fd4e3f1c408b936ff5863a0c6143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eafaf7992004c35a0a69e0b1474f5cc",
      "placeholder": "​",
      "style": "IPY_MODEL_d14ca06bf8db40dcb97a1758a413480b",
      "value": " 1000/1000 [00:02&lt;00:00, 374.21it/s]"
     }
    },
    "08ab5e6c7b08494d9130641665b1566a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1209f2cc5b294d72b8514cf1980184ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d9b412e680f4623b908a7c0bb1a54c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22b5f2ff37f64856936830a1bb31df37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d9b412e680f4623b908a7c0bb1a54c7",
      "placeholder": "​",
      "style": "IPY_MODEL_492f185bc8e84c5a939eec09c0b857a0",
      "value": " 513M/513M [00:05&lt;00:00, 225MB/s]"
     }
    },
    "24935959b22245f796b18a899907fd50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b101f448c0946db91f1b90d02e418b2",
       "IPY_MODEL_30b9f1be12af4f1d8e2ede7964f36fd5",
       "IPY_MODEL_0723fd4e3f1c408b936ff5863a0c6143"
      ],
      "layout": "IPY_MODEL_9bb04948bc0f4ebf9a2822913389a26f"
     }
    },
    "26fd0fd3124c4778b4c17757c40cbb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1209f2cc5b294d72b8514cf1980184ef",
      "max": 513256494,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ae0c0f3afe24148bf56de789f608311",
      "value": 513256494
     }
    },
    "271a0ba2420e438abe4e4993896f57f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77722495fe084fd2897b1e815d2f9fee",
       "IPY_MODEL_c6e0c1192b4144af8d71af9aa62c4e52",
       "IPY_MODEL_dc9344d479714251b5313cd6e48bb1d6"
      ],
      "layout": "IPY_MODEL_bd9acf347382422e862ae2fff89045c9"
     }
    },
    "2ea3be2cb9c347a0b7f433c903d9723b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff8c5fedb974ab1a667172fbb7ddd35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_008527e6c5804d8c96d5b9184007f024",
      "placeholder": "​",
      "style": "IPY_MODEL_3a88a05ef65443e09eccba1b7ef1fcae",
      "value": "config.json: "
     }
    },
    "30b9f1be12af4f1d8e2ede7964f36fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_598fc31b289b448b8aef00ede79a41b2",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e97ace3e53884202a85b295bdd8bcb39",
      "value": 1000
     }
    },
    "315dbc7cb1e141f18e23336a5dcc661b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_572bb05aa8074b629f9a9da38bba9887",
      "placeholder": "​",
      "style": "IPY_MODEL_ed017209de9541ab983f4dd5bccdc065",
      "value": " 513M/513M [00:04&lt;00:00, 217MB/s]"
     }
    },
    "3a88a05ef65443e09eccba1b7ef1fcae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b101f448c0946db91f1b90d02e418b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db1a60166372467594cefa0a1dcf7607",
      "placeholder": "​",
      "style": "IPY_MODEL_c5b8744fa37f44a8958dca9e3be923ad",
      "value": "100%"
     }
    },
    "3f6f206bb7f744e7ad0277a1f7b929d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ff8c5fedb974ab1a667172fbb7ddd35",
       "IPY_MODEL_8ec788e75c4645a484b84bd1d382ef26",
       "IPY_MODEL_bdde90730b3547c49e7ea58dc94378e0"
      ],
      "layout": "IPY_MODEL_a08c007a91854ad79b7f0a9a065b3f1c"
     }
    },
    "40682afc0a524900bd406fb6f63bf356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86c10111ceb348cd90e2b74fc0ae62a7",
      "placeholder": "​",
      "style": "IPY_MODEL_92e889204aba40bab5028b7670ef6c37",
      "value": "100%"
     }
    },
    "44377e80fb364395b0bf02567e283a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44776cf11e6b4509b3dfe330de1dca3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "492f185bc8e84c5a939eec09c0b857a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4baadae00ad547429cfab3bcdd613d9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c84995329f5496f88419760b160eff9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d0c412f0f954c1ebf90aee3e44fde82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4edbac73dff74b6ca054dc6dff964789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62d8e675246043dcad3006f40a5217f2",
       "IPY_MODEL_26fd0fd3124c4778b4c17757c40cbb80",
       "IPY_MODEL_315dbc7cb1e141f18e23336a5dcc661b"
      ],
      "layout": "IPY_MODEL_65554f82ec1c4662801ddf0ffe76d439"
     }
    },
    "572bb05aa8074b629f9a9da38bba9887": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "598fc31b289b448b8aef00ede79a41b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e19cb672dd04e14a12be11597f5eb9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2470356eb004b7a8643d819262f07a7",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d0c412f0f954c1ebf90aee3e44fde82",
      "value": 200
     }
    },
    "62d8e675246043dcad3006f40a5217f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c84995329f5496f88419760b160eff9",
      "placeholder": "​",
      "style": "IPY_MODEL_c223ee701aaf4cc788fb9ec1c13fde53",
      "value": "model.safetensors: 100%"
     }
    },
    "635ddac3e64f40918f23b8370e44111d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65554f82ec1c4662801ddf0ffe76d439": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ae0c0f3afe24148bf56de789f608311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d603d5271c54378a1302747bce81ed0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7216a312d16b4a28bc020c4f447851d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ea3be2cb9c347a0b7f433c903d9723b",
      "placeholder": "​",
      "style": "IPY_MODEL_44776cf11e6b4509b3dfe330de1dca3f",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "77722495fe084fd2897b1e815d2f9fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d603d5271c54378a1302747bce81ed0",
      "placeholder": "​",
      "style": "IPY_MODEL_f4cc3e0c6e024eab9be56593ef76cd89",
      "value": "tokenizer.json: "
     }
    },
    "8122ed7d8b7d457391b0f50f1e23d72b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "82acb7607391429ba02249587f16ed5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "846e02b8870845c2bd9cc3530f6393b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40682afc0a524900bd406fb6f63bf356",
       "IPY_MODEL_5e19cb672dd04e14a12be11597f5eb9a",
       "IPY_MODEL_bb76f7cdbc194cdbb948f7e618d27433"
      ],
      "layout": "IPY_MODEL_e901e35d78cd4971826d37045897d4a0"
     }
    },
    "86c10111ceb348cd90e2b74fc0ae62a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eafaf7992004c35a0a69e0b1474f5cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ec788e75c4645a484b84bd1d382ef26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed845a724be445b6b0a1736125ab1abb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e66723cdcc149ed806568661ed8890e",
      "value": 1
     }
    },
    "92e889204aba40bab5028b7670ef6c37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bb04948bc0f4ebf9a2822913389a26f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e66723cdcc149ed806568661ed8890e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a08c007a91854ad79b7f0a9a065b3f1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2470356eb004b7a8643d819262f07a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeae18ddbc2a42c2b5dc1badbab72e48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb76f7cdbc194cdbb948f7e618d27433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_635ddac3e64f40918f23b8370e44111d",
      "placeholder": "​",
      "style": "IPY_MODEL_44377e80fb364395b0bf02567e283a3f",
      "value": " 200/200 [00:00&lt;00:00, 554.57it/s]"
     }
    },
    "bd9acf347382422e862ae2fff89045c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdde90730b3547c49e7ea58dc94378e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc7fc7b9cdca4cb89bd55471e05d371d",
      "placeholder": "​",
      "style": "IPY_MODEL_ff9312a4d04248d99919a8a947f2e241",
      "value": " 1.00k/? [00:00&lt;00:00, 17.6kB/s]"
     }
    },
    "c0e11d3e90354a96b25df6ec58f70e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7216a312d16b4a28bc020c4f447851d2",
       "IPY_MODEL_f9827ac8387e48a2bd079af05ff2e2ec",
       "IPY_MODEL_22b5f2ff37f64856936830a1bb31df37"
      ],
      "layout": "IPY_MODEL_4baadae00ad547429cfab3bcdd613d9b"
     }
    },
    "c223ee701aaf4cc788fb9ec1c13fde53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5b8744fa37f44a8958dca9e3be923ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6e0c1192b4144af8d71af9aa62c4e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8122ed7d8b7d457391b0f50f1e23d72b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aeae18ddbc2a42c2b5dc1badbab72e48",
      "value": 1
     }
    },
    "cc7fc7b9cdca4cb89bd55471e05d371d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d14ca06bf8db40dcb97a1758a413480b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2becb4c2cf7476ab35ccbc476772032": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db1a60166372467594cefa0a1dcf7607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc9344d479714251b5313cd6e48bb1d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ab5e6c7b08494d9130641665b1566a",
      "placeholder": "​",
      "style": "IPY_MODEL_deb7260e6e80440680f99aa12e4883d0",
      "value": " 2.83M/? [00:00&lt;00:00, 25.7MB/s]"
     }
    },
    "deb7260e6e80440680f99aa12e4883d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e901e35d78cd4971826d37045897d4a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e97ace3e53884202a85b295bdd8bcb39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed017209de9541ab983f4dd5bccdc065": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed845a724be445b6b0a1736125ab1abb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "f4cc3e0c6e024eab9be56593ef76cd89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9827ac8387e48a2bd079af05ff2e2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82acb7607391429ba02249587f16ed5a",
      "max": 513302779,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2becb4c2cf7476ab35ccbc476772032",
      "value": 513302779
     }
    },
    "ff9312a4d04248d99919a8a947f2e241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
